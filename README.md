Steps to run this code

1. Run the frontend - npm run dev
2. run the backend - 
        a. source venv/bin/activate
        b. python3 -m venv venv
        c. python3 app.py

3. Run the ollama model
         a. start the app ollama

.env data 

MONGO_URI="your mongo db URI"
JWT_SECRET_KEY=your-secret-key 


üß† 1Ô∏è‚É£ Ollama has one single local server process

When you run:

ollama serve


or simply open the Ollama desktop app,
it automatically starts a local API server at:

http://localhost:11434


That server exposes all endpoints for both:

/api/generate ‚Üí for generating text (LLM)

/api/embeddings ‚Üí for generating embeddings (vector representation)


![alt text](<Screenshot 2025-11-03 at 4.57.14‚ÄØPM.png>) ![alt text](<Screenshot 2025-11-03 at 4.56.46‚ÄØPM.png>)

![alt text](<Screenshot 2025-11-04 at 4.06.39‚ÄØPM.png>) ![alt text](<Screenshot 2025-11-04 at 4.06.46‚ÄØPM.png>) ![alt text](<Screenshot 2025-11-04 at 4.06.53‚ÄØPM.png>) ![alt text](<Screenshot 2025-11-04 at 4.07.22‚ÄØPM.png>) ![alt text](<Screenshot 2025-11-04 at 4.07.29‚ÄØPM.png>) ![alt text](<Screenshot 2025-11-04 at 4.07.37‚ÄØPM.png>) ![alt text](<Screenshot 2025-11-04 at 4.07.59‚ÄØPM.png>) ![alt text](<Screenshot 2025-11-04 at 4.08.28‚ÄØPM.png>)